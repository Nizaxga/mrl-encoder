{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e3239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088ed96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "LATENT_DIM = 128\n",
    "Z1_DIM = 32  \n",
    "Z2_DIM = 32  \n",
    "Z3_DIM = 64\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb31867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(img_tensor, title=\"\"):\n",
    "    img_tensor = img_tensor * 0.5 + 0.5  \n",
    "    grid = make_grid(img_tensor.detach().cpu(), nrow=8)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c648867",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=LATENT_DIM):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128 * 4 * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (128, 4, 4)),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # 8x8\n",
    "            nn.BatchNorm2d(64), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),   # 16x16\n",
    "            nn.BatchNorm2d(32), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1),   # 32x32\n",
    "            nn.BatchNorm2d(16), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 3, 4, 2, 1),    # 64x64\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 4, 2, 1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(16, 32, 4, 2, 1), nn.BatchNorm2d(32), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
    "            nn.Flatten(), nn.Linear(128 * 4 * 4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, LATENT_DIM)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92ddad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_loss(real_out, fake_out):\n",
    "    return -torch.mean(real_out) + torch.mean(fake_out)\n",
    "\n",
    "def contrastive_loss(z1, z2, temperature=0.07):\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    logits = torch.matmul(z1, z2.T) / temperature\n",
    "    labels = torch.arange(z1.size(0), device=z1.device)\n",
    "    return F.cross_entropy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "335a31f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileURLRetrievalError",
     "evalue": "Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM\n\nbut Gdown can't. Please check connections and permissions.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileURLRetrievalError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/encoder/.venv/lib/python3.13/site-packages/gdown/download.py:267\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     url = \u001b[43mget_url_from_gdrive_confirmation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m FileURLRetrievalError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/encoder/.venv/lib/python3.13/site-packages/gdown/download.py:53\u001b[39m, in \u001b[36mget_url_from_gdrive_confirmation\u001b[39m\u001b[34m(contents)\u001b[39m\n\u001b[32m     52\u001b[39m         error = m.groups()[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m FileURLRetrievalError(error)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url:\n",
      "\u001b[31mFileURLRetrievalError\u001b[39m: Too many users have viewed or downloaded this file recently. Please try accessing the file again later. If the file you are trying to access is particularly large or is shared with many people, it may take up to 24 hours to be able to view or download the file. If you still can't access a file after 24 hours, contact your domain administrator.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileURLRetrievalError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m transform = transforms.Compose([\n\u001b[32m      2\u001b[39m transforms.Resize(\u001b[32m64\u001b[39m),\n\u001b[32m      3\u001b[39m     transforms.CenterCrop(\u001b[32m64\u001b[39m),\n\u001b[32m      4\u001b[39m     transforms.ToTensor(),\n\u001b[32m      5\u001b[39m     transforms.Normalize([\u001b[32m0.5\u001b[39m]*\u001b[32m3\u001b[39m, [\u001b[32m0.5\u001b[39m]*\u001b[32m3\u001b[39m)\n\u001b[32m      6\u001b[39m ])\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m dataset = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCelebA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m smiling_idx, bald_idx = \u001b[32m31\u001b[39m, \u001b[32m4\u001b[39m\n\u001b[32m      9\u001b[39m indices = [i \u001b[38;5;28;01mfor\u001b[39;00m i, attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset.attr) \u001b[38;5;28;01mif\u001b[39;00m attr[smiling_idx] == \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m attr[bald_idx] == \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/encoder/.venv/lib/python3.13/site-packages/torchvision/datasets/celeba.py:85\u001b[39m, in \u001b[36mCelebA.__init__\u001b[39m\u001b[34m(self, root, split, target_type, transform, target_transform, download)\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mtarget_transform is specified but target_type is empty\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_integrity():\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/encoder/.venv/lib/python3.13/site-packages/torchvision/datasets/celeba.py:160\u001b[39m, in \u001b[36mCelebA.download\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (file_id, md5, filename) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.file_list:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[43mdownload_file_from_google_drive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_folder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m extract_archive(os.path.join(\u001b[38;5;28mself\u001b[39m.root, \u001b[38;5;28mself\u001b[39m.base_folder, \u001b[33m\"\u001b[39m\u001b[33mimg_align_celeba.zip\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/encoder/.venv/lib/python3.13/site-packages/torchvision/datasets/utils.py:206\u001b[39m, in \u001b[36mdownload_file_from_google_drive\u001b[39m\u001b[34m(file_id, root, filename, md5)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_integrity(fpath, md5):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[43mgdown\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUSER_AGENT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_integrity(fpath, md5):\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFile not found or corrupted.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/encoder/.venv/lib/python3.13/site-packages/gdown/download.py:278\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[39m\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m FileURLRetrievalError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    269\u001b[39m         message = (\n\u001b[32m    270\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFailed to retrieve file url:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    271\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou may still be able to access the file from the browser:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    276\u001b[39m             url_origin,\n\u001b[32m    277\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m FileURLRetrievalError(message)\n\u001b[32m    280\u001b[39m filename_from_url = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    281\u001b[39m last_modified_time = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mFileURLRetrievalError\u001b[39m: Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM\n\nbut Gdown can't. Please check connections and permissions."
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "dataset = datasets.CelebA(root=\"../data\", split=\"train\", target_type=\"attr\", download=True, transform=transform)\n",
    "smiling_idx, bald_idx = 31, 4\n",
    "indices = [i for i, attr in enumerate(dataset.attr) if attr[smiling_idx] == 1 or attr[bald_idx] == 1]\n",
    "subset = Subset(dataset, indices)\n",
    "dataloader = DataLoader(subset, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18eb9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileURLRetrievalError",
     "evalue": "Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM\n\nbut Gdown can't. Please check connections and permissions.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileURLRetrievalError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/encoder/.venv/lib/python3.13/site-packages/gdown/download.py:267\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     url = \u001b[43mget_url_from_gdrive_confirmation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m FileURLRetrievalError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/encoder/.venv/lib/python3.13/site-packages/gdown/download.py:53\u001b[39m, in \u001b[36mget_url_from_gdrive_confirmation\u001b[39m\u001b[34m(contents)\u001b[39m\n\u001b[32m     52\u001b[39m         error = m.groups()[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m FileURLRetrievalError(error)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url:\n",
      "\u001b[31mFileURLRetrievalError\u001b[39m: Too many users have viewed or downloaded this file recently. Please try accessing the file again later. If the file you are trying to access is particularly large or is shared with many people, it may take up to 24 hours to be able to view or download the file. If you still can't access a file after 24 hours, contact your domain administrator.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileURLRetrievalError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m D2 = Discriminator().to(DEVICE)\n\u001b[32m      4\u001b[39m D3 = Discriminator().to(DEVICE)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m dataloader, dataset = \u001b[43mload_celebA_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m opt_G = torch.optim.Adam(G.parameters(), lr=\u001b[32m2e-4\u001b[39m, betas=(\u001b[32m0.5\u001b[39m, \u001b[32m0.999\u001b[39m))\n\u001b[32m      9\u001b[39m opt_D = torch.optim.Adam(\u001b[38;5;28mlist\u001b[39m(D1.parameters()) + \u001b[38;5;28mlist\u001b[39m(D2.parameters()) + \u001b[38;5;28mlist\u001b[39m(D3.parameters()), lr=\u001b[32m2e-4\u001b[39m, betas=(\u001b[32m0.5\u001b[39m, \u001b[32m0.999\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mload_celebA_subset\u001b[39m\u001b[34m(batch_size)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_celebA_subset\u001b[39m(batch_size=\u001b[32m64\u001b[39m):\n\u001b[32m      2\u001b[39m     transform = transforms.Compose([\n\u001b[32m      3\u001b[39m         transforms.Resize(\u001b[32m64\u001b[39m),\n\u001b[32m      4\u001b[39m         transforms.CenterCrop(\u001b[32m64\u001b[39m),\n\u001b[32m      5\u001b[39m         transforms.ToTensor(),\n\u001b[32m      6\u001b[39m         transforms.Normalize([\u001b[32m0.5\u001b[39m]*\u001b[32m3\u001b[39m, [\u001b[32m0.5\u001b[39m]*\u001b[32m3\u001b[39m)\n\u001b[32m      7\u001b[39m     ])\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     dataset = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCelebA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     smiling_idx, bald_idx = \u001b[32m31\u001b[39m, \u001b[32m4\u001b[39m\n\u001b[32m     10\u001b[39m     indices = [i \u001b[38;5;28;01mfor\u001b[39;00m i, attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset.attr) \u001b[38;5;28;01mif\u001b[39;00m attr[smiling_idx] == \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m attr[bald_idx] == \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/encoder/.venv/lib/python3.13/site-packages/torchvision/datasets/celeba.py:85\u001b[39m, in \u001b[36mCelebA.__init__\u001b[39m\u001b[34m(self, root, split, target_type, transform, target_transform, download)\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mtarget_transform is specified but target_type is empty\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_integrity():\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/encoder/.venv/lib/python3.13/site-packages/torchvision/datasets/celeba.py:160\u001b[39m, in \u001b[36mCelebA.download\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (file_id, md5, filename) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.file_list:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[43mdownload_file_from_google_drive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_folder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m extract_archive(os.path.join(\u001b[38;5;28mself\u001b[39m.root, \u001b[38;5;28mself\u001b[39m.base_folder, \u001b[33m\"\u001b[39m\u001b[33mimg_align_celeba.zip\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/encoder/.venv/lib/python3.13/site-packages/torchvision/datasets/utils.py:206\u001b[39m, in \u001b[36mdownload_file_from_google_drive\u001b[39m\u001b[34m(file_id, root, filename, md5)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_integrity(fpath, md5):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[43mgdown\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUSER_AGENT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_integrity(fpath, md5):\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFile not found or corrupted.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/encoder/.venv/lib/python3.13/site-packages/gdown/download.py:278\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[39m\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m FileURLRetrievalError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    269\u001b[39m         message = (\n\u001b[32m    270\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFailed to retrieve file url:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    271\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou may still be able to access the file from the browser:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    276\u001b[39m             url_origin,\n\u001b[32m    277\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m FileURLRetrievalError(message)\n\u001b[32m    280\u001b[39m filename_from_url = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    281\u001b[39m last_modified_time = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mFileURLRetrievalError\u001b[39m: Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM\n\nbut Gdown can't. Please check connections and permissions."
     ]
    }
   ],
   "source": [
    "G = Generator(LATENT_DIM).to(DEVICE)\n",
    "D1 = Discriminator().to(DEVICE)\n",
    "D2 = Discriminator().to(DEVICE)\n",
    "D3 = Discriminator().to(DEVICE)\n",
    "\n",
    "opt_G = torch.optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "opt_D = torch.optim.Adam(list(D1.parameters()) + list(D2.parameters()) + list(D3.parameters()), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "for epoch in range(1):  # set higher for full training\n",
    "    for real_images, attrs in dataloader:\n",
    "        real_images = real_images.to(DEVICE)\n",
    "        x1 = real_images[attrs[:, 31] == 1]  # smiling\n",
    "        x2 = real_images[attrs[:, 4] == 1]   # bald\n",
    "        if len(x1) == 0 or len(x2) == 0: continue\n",
    "\n",
    "        z = torch.randn(x1.size(0), LATENT_DIM).to(DEVICE)\n",
    "        z1, z2, z3 = z[:, :Z1_DIM], z[:, Z1_DIM:Z1_DIM+Z2_DIM], z[:, -Z3_DIM:]\n",
    "\n",
    "        fake_x1 = G(torch.cat([z1, torch.zeros_like(z2), z3], dim=1))\n",
    "        fake_x2 = G(torch.cat([torch.zeros_like(z1), z2, z3], dim=1))\n",
    "        fake_xy = G(torch.cat([z1, z2, z3], dim=1))\n",
    "\n",
    "        D1.zero_grad(), D2.zero_grad(), D3.zero_grad()\n",
    "        loss_d1 = gan_loss(D1(x1[:len(fake_x1)]), D1(fake_x1.detach()))\n",
    "        loss_d2 = gan_loss(D2(x2[:len(fake_x2)]), D2(fake_x2.detach()))\n",
    "        loss_d3 = gan_loss(D3(real_images[:len(fake_xy)]), D3(fake_xy.detach()))\n",
    "        (loss_d1 + loss_d2 + loss_d3).backward()\n",
    "        opt_D.step()\n",
    "\n",
    "        G.zero_grad()\n",
    "        loss_g = -D1(fake_x1).mean() - D2(fake_x2).mean() - D3(fake_xy).mean()\n",
    "        loss_g.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}: D Loss = {loss_d1.item() + loss_d2.item() + loss_d3.item():.4f}, G Loss = {loss_g.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z = torch.randn(16, LATENT_DIM).to(DEVICE)\n",
    "z1, z2, z3 = z[:, :Z1_DIM], z[:, Z1_DIM:Z1_DIM+Z2_DIM], z[:, -Z3_DIM:]\n",
    "img_x1 = G(torch.cat([z1, torch.zeros_like(z2), z3], dim=1))\n",
    "img_x2 = G(torch.cat([torch.zeros_like(z1), z2, z3], dim=1))\n",
    "img_xy = G(torch.cat([z1, z2, z3], dim=1))\n",
    "\n",
    "show_images(img_x1, title=\"Generated Domain X1 (e.g., Smiling)\")\n",
    "show_images(img_x2, title=\"Generated Domain X2 (e.g., Bald)\")\n",
    "show_images(img_xy, title=\"Generated Intersection X1∩X2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
