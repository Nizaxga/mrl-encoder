{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf21ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEN\n",
    "\n",
    "class TextAutoencoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.decoder = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        _, (hidden, _) = self.encoder(embedded)\n",
    "        \n",
    "        # Decoder input could be the same as input during training (teacher forcing)\n",
    "        decoder_input = self.embedding(input_seq)\n",
    "        output, _ = self.decoder(decoder_input, (hidden, torch.zeros_like(hidden)))\n",
    "        \n",
    "        logits = self.output_layer(output)\n",
    "        return logits\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
